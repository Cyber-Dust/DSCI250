{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "H3_volk_dasean.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN48Suor8/YNtn+UF3Ui4uu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cyber-Dust/DSCI250/blob/main/H3_volk_dasean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ppOLkR_WOA6"
      },
      "source": [
        "Dasean Volk, dvolk@usc.edu\n",
        "\n",
        "Fall 2021, DSCI 250\n",
        "\n",
        "Homework #3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b9lSnMm7jY3"
      },
      "source": [
        "Homework Notes\n",
        "Train the network so that is has weights that it calculates. As you train it should get closer and closer to 0. Do not feed it new data.\n",
        "The code already does the training. Do it with a calculator, do not wirte code. Show him the and, or, xor results. \n",
        "\n",
        "Q2: do it for the data we have, feed the 101 into the equation on a hand calculator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t_WKg8vV_3p",
        "outputId": "099380af-6d29-4640-ac4f-d8ff3069271c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1.0 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        self.input      = x\n",
        "        self.weights1   = np.random.rand(self.input.shape[1],4) \n",
        "        self.weights2   = np.random.rand(4,1)                 \n",
        "        self.y          = y\n",
        "        self.output     = np.zeros(self.y.shape)\n",
        "\n",
        "    def feedforward(self):\n",
        "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
        "\n",
        "    def backprop(self):\n",
        "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
        "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
        "        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * \n",
        "                                            sigmoid_derivative(self.layer1)))\n",
        "\n",
        "        # update the weights with the derivative (slope) of the loss function\n",
        "        self.weights1 += d_weights1\n",
        "        self.weights2 += d_weights2\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X = np.array([[0,0,1],\n",
        "                  [0,1,1],\n",
        "                  [1,0,1],\n",
        "                  [1,1,1]])\n",
        "    y = np.array([[0],[1],[1],[0]])\n",
        "    nn = NeuralNetwork(X,y)\n",
        "\n",
        "    for i in range(10000):\n",
        "        nn.feedforward()\n",
        "        nn.backprop()\n",
        "\n",
        "\n",
        "    print(nn.weights1)\n",
        "    print(nn.weights2)\n",
        "    print(nn.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.20159548  3.19227181  7.4402347   2.38699948]\n",
            " [-1.72709034  4.07388805  7.0283079   3.41523078]\n",
            " [ 2.11380999 -5.6280187  -3.35432516 -4.52686116]]\n",
            "[[-5.73167376]\n",
            " [-7.8338544 ]\n",
            " [12.03262855]\n",
            " [-6.64875403]]\n",
            "[[0.00810593]\n",
            " [0.9950759 ]\n",
            " [0.99220969]\n",
            " [0.00633841]]\n"
          ]
        }
      ]
    }
  ]
}